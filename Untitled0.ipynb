{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNytMRzMWOz/hxp8iTki3kQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marosamipe27/SeminarioDeProyectos_WordCount_MRSMP/blob/copy/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "apAEPSpsHJQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eb4a7d8-5520-4763-ac6b-a685475e55d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Import and download packages\n",
        "import requests\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from collections import Counter\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get The War Of The Worlds HTML\n",
        "r = requests.get('https://www.gutenberg.org/cache/epub/36/pg36-images.html')\n",
        "\n",
        "# Set the correct text encoding of the HTML page\n",
        "r.encoding = 'utf-8'"
      ],
      "metadata": {
        "id": "VNVQ8oPCHkA1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the HTML from the request object\n",
        "html = r.text\n",
        "\n",
        "# Print 1000 characters in html\n",
        "print(html[15000:16000])"
      ],
      "metadata": {
        "id": "dmm3aG4uHrWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b4c543-fd82-443c-ab0d-83793b51e6a0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "led to interpret the fluctuating appearances\r\n",
            "of the markings they mapped so well. All that time the Martians must have been\r\n",
            "getting ready.\r\n",
            "</p>\r\n",
            "<p>\r\n",
            "During the opposition of 1894 a great light was seen on the illuminated part of\r\n",
            "the disk, first at the Lick Observatory, then by Perrotin of Nice, and then by\r\n",
            "other observers. English readers heard of it first in the issue of\r\n",
            "<i>Nature</i> dated August 2. I am inclined to think that this blaze may have\r\n",
            "been the casting of the huge gun, in the vast pit sunk into their planet, from\r\n",
            "which their shots were fired at us. Peculiar markings, as yet unexplained, were\r\n",
            "seen near the site of that outbreak during the next two oppositions.\r\n",
            "</p>\r\n",
            "<p>\r\n",
            "The storm burst upon us six years ago now. As Mars approached opposition,\r\n",
            "Lavelle of Java set the wires of the astronomical exchange palpitating with the\r\n",
            "amazing intelligence of a huge outbreak of incandescent gas upon the planet. It\r\n",
            "had occurred towards midnight of the twelfth; and the spectr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a BeautifulSoup object from the HTML\n",
        "html_soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "# Get the text out of the soup\n",
        "twotw_text = html_soup.get_text()\n",
        "# Create a tokenizer\n",
        "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = tokenizer.tokenize(twotw_text)\n",
        "# Create a list called words containing all tokens transformed to lowercase\n",
        "words = [token.lower() for token in tokens]\n",
        "\n",
        "# Print out the first eight words\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZgSqqhC8Chs",
        "outputId": "5b1e73e4-37d8-406f-cc68-03dade520863"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'war', 'of']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the English stop words from nltk\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# Print out the first eight stop words\n",
        "stop_words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGVvd35v8PxK",
        "outputId": "25fc4081-02e9-4910-cd79-da0a3524cdc3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list words_ns containing all words that are in words but not in stop_words\n",
        "words_no_stop = [word for word in words if word not in stop_words]\n",
        "\n",
        "# Print the first five words_no_stop to check that stop words are gone\n",
        "words_no_stop[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iZvLoOj8fqM",
        "outputId": "6658f896-67b3-42d6-91dd-94896a31ccb6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['project', 'gutenberg', 'ebook', 'war', 'worlds']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a Counter object from our processed list of words\n",
        "count_total = Counter(words_no_stop)\n",
        "\n",
        "# Store ten most common words and their counts as top_ten\n",
        "top_ten = count_total.most_common(10)\n",
        "\n",
        "# Print the top ten words and their counts\n",
        "print(top_ten)\n",
        "\n",
        "# Saving top 100 to CSV file\n",
        "# N.b. change filename to reflect chosen book\n",
        "filename = 'words_thewaroftheworlds.csv'\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "\n",
        "    writer = csv.writer(csvfile, delimiter=',',  quotechar='\"',\n",
        "                                     quoting=csv.QUOTE_MINIMAL)\n",
        "    writer.writerow([\"word\",\"count\"])\n",
        "    for key, count in count_total.most_common(100):\n",
        "        word = key\n",
        "        writer.writerow([word, count])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlWdKsqh8jYi",
        "outputId": "077af6c8-6eb3-4ade-eb89-9a5b6357e5b9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('one', 204), ('upon', 174), ('martians', 166), ('said', 166), ('people', 162), ('came', 151), ('saw', 131), ('towards', 129), ('man', 127), ('time', 122)]\n"
          ]
        }
      ]
    }
  ]
}